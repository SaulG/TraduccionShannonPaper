2. Con cualesquiera dos variables $x$, $y$ tenemos:
\begin{equation}
H\left ( x,y \right )\leq H\left ( x \right )+H\left ( y \right )
\end{equation}
con igualdad si (y solo si) $x$ y $y$ son independientes, por ejemplo,
$p\left ( x,y \right )=p\left ( x \right )p\left ( y \right )$
(adem\'{a}s posiblemente un conjunto de puntos de probabilidad cero)

3. Considere una operaci\'{o}n de promedio generalizada del siguiente tipo:
\begin{equation}
{p}'\left ( y \right )=\int a\left ( x,y \right )p\left ( x \right ) \diff x 
\end{equation}
con
\begin{equation}
\int a\left ( x,y \right ) \diff x =\int a\left ( x,y \right ) \diff y =1, 
\,  a\left ( x,y \right )\geq 0
\end{equation}
Entonces la entropia de la distribuci\'{o}n promediada ${p}'\left ( y
\right )$ es igual a o mayor que la distribuci\'{o}n original $p\left
( y \right )$. 

4. Tenemos:

\begin{equation}
H\left ( x,y \right )=H\left ( x \right )+H_{x}\left ( y \right )=H\left ( y \right )+H_{y}\left ( x \right )
\end{equation}
y
\begin{equation}
H_x{}\left ( y \right )\leq H\left ( y \right )
\end{equation}

5. Dejamos $p\left ( y \right )$ ser una distribuci\'{o}n unidimensional. La forma de $p\left ( y \right )$ dando una m\'{a}xima entropia sujeto a la condici\'{o}n de que la desviaci\'{o}n est\'{a}ndar de x es fija en $\sigma $ es Gaussiana. Para demostrar esto debemos maximizar:
\begin{equation}
H\left ( x \right )=-\int p\left ( x \right )\log p\left ( x \right ) \diff x 
\end{equation}
con
\begin{equation}
\sigma^{2}=\int p\left ( x \right )x^{2} \diff x  \:\:\:\:\: \textup{y} \:\:\:\:\: 1=\int p\left ( x \right ) \diff x 
\end{equation}
como l\'{i}mites. \'{E}sto requiere, por el c\'{a}lculo de variaciones, maximizar:
\begin{equation}
\int \left [ -p\left ( x \right ) \log p\left ( x \right ) + \lambda p\left ( x \right ) x^{2} + \mu p\left ( x \right )\right ] \diff x 
\end{equation}

La condici\'{o}n para \'{e}sto es
\begin{equation}
-1-\log p\left ( x \right )+\lambda x^{2}+\mu =0
\end{equation}
y consecuentemente (ajustando las constantes para satisfacer los l\'{i}mites)
\begin{equation}
p\left ( x \right )=\frac{1}{\sqrt{2\pi \sigma }}e^{-\left ( x^{2}/2\sigma ^{2} \right )}
\end{equation}

Del mismo modo en $n$ dimensiones, supongamos que los momentos de
segundo orden de $p\left ( x_{1}, \ldots ,x_{n} \right )$ son fijos en
$A_{ij}$:
\begin{equation}
A_{ij}=\int \cdots \int x_{i}x_{j}p\left ( x_{1}, \ldots ,x_{n} \right ) \diff x _{1}\cdots  \diff x_{n}
\end{equation}

Entonces la m\'{a}xima entropia ocurre (por un c\'{a}lculo similar)
cuando $p\left ( x_{1}, \ldots ,x_{n} \right )$ es la distribuci\'{o}n
Gaussiana $n$ dimensional con los momentos de segundo orden $A_{ij}$
\begin{equation}
H\left ( x \right )=\log \sqrt{2\pi e\sigma }
\end{equation}

a\\

\begin{equation}
p\left ( x \right )=\frac{1}{\sqrt{2\pi \sigma }}e^{-\left ( x^{2}/2\sigma ^{2} \right )}
\end{equation}
\begin{equation}
-\log p\left ( x \right )=\log \sqrt{2\pi \sigma }+\frac{x^{2}}{2\sigma ^{2}}
\end{equation}
\begin{equation}
H\left ( x \right )=-\int p\left ( x \right )\log p\left ( x \right ) \diff x 
\end{equation}
\begin{equation}
=\int p\left ( x \right )\log \sqrt{2\pi \sigma } \diff x +\int p\left ( x \right )\frac{x^{2}}{2\sigma ^{2}} \diff x 
\end{equation}
\begin{equation}
=\log \sqrt{2\pi \sigma }+\frac{\sigma }{2\sigma ^{2}}
\end{equation}
\begin{equation}
=\log \sqrt{2\pi \sigma }+\log \sqrt{e}
\end{equation}
\begin{equation}
=\log \sqrt{2\pi e \sigma }
\end{equation}

a\\

\begin{equation}
p\left ( x_{1}, \ldots ,x_{n} \right )=\frac{\left | a_{ij} \right |^{\frac{1}{2}}}{\left ( 2\pi  \right )^{n/2}}\exp \left ( -\frac{1}{2} \sum a_{ij}x_{i}x_{j} \right)
\end{equation}

a\\

\begin{equation}
H=\log \left ( 2\pi e \right )^{n/2}\left | a_{ij} \right |^{-\frac{1}{2}}
\end{equation}

a\\

\begin{equation}
a=\int_{0}^{\infty}p\left ( x \right )x \diff x 
\end{equation}

a\\

\begin{equation}
p\left ( x \right )=\frac{1}{a}e^{-\left ( x/a \right )}
\end{equation}

a\\

\begin{equation}
H\left ( y \right )=\int \cdots \int p\left ( x_{1}, \ldots ,x_{n} \right )J\left ( \frac{x}{y} \right )\log p\left ( x_{1}, \ldots ,x_{n} \right )J\left ( \frac{x}{y} \right ) \diff y _{1}\cdots  \diff y _{n}
\end{equation}

a\\

\begin{equation}
H\left ( y \right )=H\left ( x \right )-\int \cdots \int p\left ( x_{1}, \ldots ,x_{n} \right )\log J \left ( \frac{x}{y} \right ) \diff x _{1}\cdots  \diff x _{n}
\end{equation}

a\\

\begin{equation}
y_{j}=\sum_{i}^{\:}a_{ij}x_{i}
\end{equation}

a\\

\begin{equation}
H\left ( y \right )=H\left ( x \right )+\log\left | a_{ij} \right |
\end{equation}

a\\

\begin{equation}
p\left ( x_{1}, \ldots ,x_{n}\right )
\end{equation}

a\\

\begin{equation}
{H}'=-\lim_{n\rightarrow \infty }\frac{1}{n}\int \cdots \int p\left ( x_{1}, \ldots ,x_{n}\right ) \log p\left ( x_{1}, \ldots ,x_{n}\right ) \diff x _{1} \ldots  \diff x _{n}
\end{equation}

a\\

\begin{equation}
{H}'=\log \sqrt{2\pi eN}
\end{equation}
\begin{equation}
H=W\log 2\pi eN
\end{equation}

a\\

\begin{equation}
\left | \frac{\log p}{n} - {H}'\right |< \varepsilon 
\end{equation}

a\\

\begin{equation}
\lim_{n\rightarrow \infty }\frac{\log V_{n}\left ( q \right )}{n}={H}'
\end{equation}

a\\

\begin{equation}
p\left ( x_{1}, \ldots ,x_{n}\right )=\frac{1}{\left ( 2\pi N \right )^{n/2}}\exp -\frac{1}{2N}\sum x_{i}^{2}
\end{equation}

a\\

\begin{equation}
N_{1}=\frac{1}{2\pi e}\exp 2{H}'
\end{equation}

a\\

\begin{equation}
H_{2}=H_{1}+\frac{1}{W}\int_{W}^{\:}\log \left | Y\left ( f \right ) \right |^{2}df
\end{equation}

a\\

\begin{equation}
J=\prod_{i=1}^{n}\left | Y\left ( f_{i} \right )  \right |^{2}
\end{equation}

a\\

\begin{equation}
\exp \frac{1}{W}\int_{W}^{\:}\log \left | Y\left ( f \right ) \right |^{2}df
\end{equation}

a\\



